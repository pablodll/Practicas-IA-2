{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Practica 2.2**\n",
    "#### _Alberto García Doménech - Pablo Daurell Marina_ (Grupo 10)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2 (Recuperación de información)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta práctica vamos a utilizar el dataset ```20 Newsgroup``` de Scikit-learn, que contiene textos de un foro sobres distintos temas muy variados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training texts: 11314\n",
      "Test texts: 7532\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el dataset\n",
    "train_data = fetch_20newsgroups(subset='train', shuffle=True, random_state=42)\n",
    "test_data = fetch_20newsgroups(subset='test')\n",
    "\n",
    "print(\"Training texts:\", len(train_data.data))\n",
    "print(\"Test texts:\", len(test_data.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver algunos ejemplos de los textos que hay en el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MENSAJE:\n",
      " From: shd2001@andy.bgsu.edu (Sherlette Dixon)\n",
      "Subject: Christianity & Atheism:  an update\n",
      "Organization: BGSU\n",
      "Lines: 32\n",
      "\n",
      "First, I would like to thank all who sent me their opinions on the matter\n",
      "at hand.  All advice was taken to heart, if not directly used.  My friend\n",
      "found out about the matter quite accidently.  After reading some of my\n",
      "mail, I quit from the mail reader & went about my business.  I must have\n",
      "trashed my mail improperly, because he got on the same terminal the next\n",
      "day & saw my old messages.  He thought they were responses to a post he\n",
      "placed in alt.atheism earlier that week, so he read some of them before\n",
      "realizing that they were for me.  I got a message from him the next day; he\n",
      "apologized for reading my mail & said that he did not want to appear to be\n",
      "a snoop.  He said that he would be willing to talk to me about his views &\n",
      "didn't mind doing so, especially with a friend.  So we did.  I neither\n",
      "changed his mind nor did he change mine, as that was not the point.  Now he\n",
      "knows where I'm coming from & now I know where he's coming from.  And all\n",
      "that I can do is pray for him, as I've always done.\n",
      "\n",
      "I believe the reason that he & I \"click\" instead of \"bash\" heads is because\n",
      "I see Christianity as a tool for revolution, & not a tool for maintaining\n",
      "the status quo.  To be quite blunt, I have more of a reason to reject God\n",
      "than he does just by the fact that I am an African-American female. \n",
      "Christianity & religion have been used as tools to separate my people from\n",
      "the true knowledge of our history & the wealth of our contributions to the\n",
      "world society.  The \"kitchen of heaven\" was all we had to look forward to\n",
      "during the slave days, & this mentality & second-class status still exists\n",
      "today.  I, too, have rejected\n",
      "an aspect of Christianity----that of the estabished church.  Too much\n",
      "hypocricy exists behind the walls of \"God's house\" beginning with the\n",
      "images of a white Jesus to that of the members:  praise God on Sunday &\n",
      "raise hell beginning Monday.  God-willing, I will find a church home where\n",
      "I can feel comfortable & at-home, but I don't see it happening anytime\n",
      "soon.\n",
      "\n",
      "Sherlette \n",
      "\n",
      "CLASE:  soc.religion.christian\n"
     ]
    }
   ],
   "source": [
    "print('MENSAJE:\\n',train_data.data[120])\n",
    "print('CLASE: ', train_data.target_names[train_data.target[120]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MENSAJE:\n",
      " From: ab245@cleveland.Freenet.Edu (Sam Latonia)\n",
      "Subject: Re: Need phone number for Western Digital (ESDI problem)\n",
      "Organization: Case Western Reserve University, Cleveland, Ohio (USA)\n",
      "Lines: 5\n",
      "NNTP-Posting-Host: slc10.ins.cwru.edu\n",
      "\n",
      "\n",
      "Western Digital 1-800-832-4778.....Sam\n",
      "-- \n",
      "Gosh..I think I just installed a virus..It was called MS DOS6...\n",
      "Don't copy that floppy..BURN IT...I just love Windows...CRASH...\n",
      "\n",
      "CLASE:  comp.sys.ibm.pc.hardware\n"
     ]
    }
   ],
   "source": [
    "print('MENSAJE:\\n',train_data.data[42])\n",
    "print('CLASE: ', train_data.target_names[train_data.target[42]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Bolsa de palabras binaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertimos el conjunto de datos en una bolsa de palabras, binaria y con n-gramas (1,1), usaremos como vocabulario el diccionario ```words.txt``` (https://github.com/dwyl/english-words/blob/master/words.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466551\n"
     ]
    }
   ],
   "source": [
    "# Pasamos el diccionario a una lista\n",
    "with open('words.txt') as f:\n",
    "    dictionary = f.read().splitlines()\n",
    "\n",
    "# Creamos la bolsa de palabras\n",
    "vectorizer = CountVectorizer(binary=False, ngram_range=(1,1), vocabulary=dictionary, stop_words='english')  \n",
    "\n",
    "# Entrenamos al modelo\n",
    "train_vector_data = vectorizer.fit_transform(train_data.data)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "print(len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 466551)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_vector_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_messages(data, target, target_names, n):\n",
    "    '''\n",
    "    Selecciona n mensajes de cada clase\n",
    "    Return: Matriz con una fila por cada clase y tres mensajes por cada fila\n",
    "    '''\n",
    "    messages = []\n",
    "    # Recorremos todas las clases\n",
    "    for i in range(len(target_names)):\n",
    "        # Seleccionamos las posiciones correspondientes a los mensajes de la clase i\n",
    "        indices = np.asarray(np.where(target == i)).ravel()\n",
    "\n",
    "        # Cogemos los n primeros mensajes de la clase i\n",
    "        aux = np.take(data, indices)[0:n]\n",
    "        messages.append(aux)\n",
    "    \n",
    "    return np.array(messages)\n",
    "\n",
    "def vectorize_messages(data, vectorizer, tfider=None):\n",
    "    '''\n",
    "    Recibe una matriz de textos y convierte cada texto a una bolsa de palabras,\n",
    "    usando un vectorizador previamente entrenado (y pasandolo a tfidf si se pide)\n",
    "    Return: Matriz con una fila por cada clase y en cada fila otra matriz con los mensajes vectorizados\n",
    "    '''\n",
    "    # Recorremos todas las filas (una por cada clase)\n",
    "    vector_data = []\n",
    "    for i in range(np.shape(data)[0]):\n",
    "        aux = vectorizer.transform(data[i, :]) # Vectorizamos el mensaje\n",
    "        \n",
    "        if tfider:\n",
    "            aux = tfider.transform(aux) # Lo convertimos a tfidf\n",
    "            \n",
    "        vector_data.append(aux)\n",
    "        \n",
    "    return np.array(vector_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos, del conjunto de test, 3 mensajes de cada una de las 20 clases:\n",
    "messages = select_messages(test_data.data, test_data.target, test_data.target_names, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizamos los mensajes seleccionados\n",
    "vector_messages = vectorize_messages(messages, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similitud del coseno:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a usar como consultas los mensajes seleccionados para recuperar los mensajes del conjunto de entrenamiento que más se parezcan. Con esto veremos que clases se recuperan para cada consulta y podremos calcular la precisión obtenida para cada clase.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def cosine_similarity_precission(vector_data, target, messages, target_names, X):\n",
    "    '''\n",
    "    Calcula la similitud del coseno de cada mensaje con todos los mensajes de \"data\" y\n",
    "    y calcula la precision de cada clase, a un nivel de exhaustividad X.\n",
    "    '''\n",
    "    for i in range(len(messages)): # Recorremos cada clase\n",
    "        precission = 0\n",
    "        for m in messages[i]: # Recorremos cada mensaje\n",
    "            # Calculamos la similitud del coseno de m con los textos de entrenamiento\n",
    "            cos_sim = cosine_similarity(m, vector_data).ravel()\n",
    "\n",
    "            # Ordenamos los resultados y cogemos los indices de los X mayores resultados\n",
    "            max_args = np.flip(np.argsort(cos_sim))[0:X]\n",
    "\n",
    "            #  max_values = np.take(cos_sim, max_args)         \n",
    "            #  Recuperamos los mensajes con mayor similitud\n",
    "            # retrieved_docs = np.take(data, max_args)\n",
    "\n",
    "            # Identificamos la clase de los mensajes con mayor similitud\n",
    "            retrieved_classes = np.take(target, max_args)\n",
    "\n",
    "            # Calculamos la precision (%) para este mensaje y lo acumulamos a las anteriores\n",
    "            precission += (np.count_nonzero(retrieved_classes == i) / len(retrieved_classes)) * 100\n",
    "\n",
    "\n",
    "        # Calculamos la media de los porcentajes obtenidos\n",
    "        precission /= np.shape(vector_messages[i])[0]\n",
    "        \n",
    "        print('Class {}:'.format(i), target_names[i], ' Precission: ', precission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando la función que acabamos de definir, vamos a calcular la precisión media de cada clase a un nivel de exhaustividad 3 (es decir, recuperando 3 mensajes del conjunto de entrenamiento) y a nivel 10 (recuperando 10 mensajes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: alt.atheism  Precission:  33.333333333333336\n",
      "Class 1: comp.graphics  Precission:  22.222222222222218\n",
      "Class 2: comp.os.ms-windows.misc  Precission:  22.222222222222218\n",
      "Class 3: comp.sys.ibm.pc.hardware  Precission:  55.55555555555555\n",
      "Class 4: comp.sys.mac.hardware  Precission:  0.0\n",
      "Class 5: comp.windows.x  Precission:  33.33333333333333\n",
      "Class 6: misc.forsale  Precission:  77.77777777777777\n",
      "Class 7: rec.autos  Precission:  33.333333333333336\n",
      "Class 8: rec.motorcycles  Precission:  88.88888888888887\n",
      "Class 9: rec.sport.baseball  Precission:  77.77777777777777\n",
      "Class 10: rec.sport.hockey  Precission:  66.66666666666667\n",
      "Class 11: sci.crypt  Precission:  55.55555555555554\n",
      "Class 12: sci.electronics  Precission:  44.444444444444436\n",
      "Class 13: sci.med  Precission:  77.77777777777777\n",
      "Class 14: sci.space  Precission:  77.77777777777777\n",
      "Class 15: soc.religion.christian  Precission:  77.77777777777777\n",
      "Class 16: talk.politics.guns  Precission:  55.55555555555554\n",
      "Class 17: talk.politics.mideast  Precission:  22.222222222222218\n",
      "Class 18: talk.politics.misc  Precission:  33.33333333333333\n",
      "Class 19: talk.religion.misc  Precission:  33.33333333333333\n"
     ]
    }
   ],
   "source": [
    "# Precision con nivel de exhaustividad = 3\n",
    "cosine_similarity_precission(train_vector_data, train_data.target, vector_messages, train_data.target_names, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: alt.atheism  Precission:  23.333333333333332\n",
      "Class 1: comp.graphics  Precission:  20.0\n",
      "Class 2: comp.os.ms-windows.misc  Precission:  30.0\n",
      "Class 3: comp.sys.ibm.pc.hardware  Precission:  50.0\n",
      "Class 4: comp.sys.mac.hardware  Precission:  6.666666666666667\n",
      "Class 5: comp.windows.x  Precission:  30.0\n",
      "Class 6: misc.forsale  Precission:  56.666666666666664\n",
      "Class 7: rec.autos  Precission:  30.0\n",
      "Class 8: rec.motorcycles  Precission:  73.33333333333333\n",
      "Class 9: rec.sport.baseball  Precission:  76.66666666666667\n",
      "Class 10: rec.sport.hockey  Precission:  56.666666666666664\n",
      "Class 11: sci.crypt  Precission:  36.666666666666664\n",
      "Class 12: sci.electronics  Precission:  50.0\n",
      "Class 13: sci.med  Precission:  53.333333333333336\n",
      "Class 14: sci.space  Precission:  73.33333333333333\n",
      "Class 15: soc.religion.christian  Precission:  50.0\n",
      "Class 16: talk.politics.guns  Precission:  40.0\n",
      "Class 17: talk.politics.mideast  Precission:  26.666666666666668\n",
      "Class 18: talk.politics.misc  Precission:  23.333333333333332\n",
      "Class 19: talk.religion.misc  Precission:  16.666666666666668\n"
     ]
    }
   ],
   "source": [
    "# Precision con nivel de exhaustividad = 10\n",
    "cosine_similarity_precission(train_vector_data, train_data.target, vector_messages, train_data.target_names, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Hay una gran diferencia entre los valores de precision medios de las diferentes clases, siendo la mayor diferencia de un 88.88% con un nivel de exhaustividad 3 y de un 70% con un nivel de exhaustividad de 10.    \n",
    "Esta clara diferencia puede venir por la ausencia de terminos especificos de la clase que estamos buscando en las consultas lo que puede llevar a una confusión entre clases. Por ejemplo, la clase con menor precisión es _comp.sys.mac.hardware_ con un 0% de precisión con nivel 3 de exhaustividad y un 6.67% con nivel 10, este nivel tan bajo de precisión seguramente se deba a que las consultas elegidas se confunden con otras clases que traten de temas relacionados con informatica, como es el caso de _comp.sys.ibm.pc.hardware_, _comp.os.ms-windows.misc_, etc.            \n",
    "Mientras que las clases que mejor precisión media tienen (_rec.motorcycles , rec.sport.baseball_) seguramente se deba a que las consultas tienen términos más específicos que las clasifiquen como las clases a las que pertenecen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Seleccionamos un mensaje de la clase con peor precision (_com.sys.mac.hardware_) y vemos que mensajes se han recuperado con él para poder observar más en detalle que puede ser el causante de los malos resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worst_class_precission(data, vector_data, target, message, vector_message, target_names, X):\n",
    "    '''\n",
    "    Dado un mensaje, recupera los X mensajes de \"data\" \n",
    "    y los muestra junto a sus clases correspondientes\n",
    "    '''\n",
    "    # Calculamos la similitud del coseno de m con los textos de entrenamiento\n",
    "    cos_sim = cosine_similarity(vector_message, vector_data).ravel()\n",
    "\n",
    "    # Ordenamos los resultados y cogemos los indices de los X mayores resultados\n",
    "    max_args = np.flip(np.argsort(cos_sim))[0:X]\n",
    "\n",
    "    # Identificamos la clase de los mensajes con mayor similitud\n",
    "    retrieved_classes = np.take(target, max_args)\n",
    "    retrieved_classes = np.take(target_names, retrieved_classes)\n",
    "    #  Recuperamos los mensajes con mayor similitud\n",
    "    retrieved_docs = np.take(data, max_args)\n",
    "    \n",
    "    print('CONSULTA:\\n',message)\n",
    "    print('*************************************')\n",
    "    print('Clases recuperadas:', retrieved_classes)\n",
    "    for i, d in enumerate(retrieved_docs):\n",
    "        print('*************************************')\n",
    "        print('Mensaje recuperado {}:\\n'.format(i), d)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONSULTA:\n",
      " From: s9131783@valiant.vut.EDU.AU (Robert B Harvey)\n",
      "Subject: Disabling the Eject on a Mac SE\n",
      "Organization: Victoria University Of Technology, Melbourne, Australia\n",
      "Lines: 13\n",
      "\n",
      "I'm trying to find a program that will stop the Macs from spitting out\n",
      "their Boot Disk. I was told one exists but I can't find it.\n",
      "\n",
      "Anyone know where I can find it?\n",
      "\n",
      "Thanks\n",
      "\n",
      "Robert Harvey\n",
      "Duty Programmer\n",
      "Information Technology\n",
      "Victoria University\n",
      "\n",
      "s9131783@valiant.vut.edu.au\n",
      "\n",
      "*************************************\n",
      "Clases recuperadas: ['comp.windows.x' 'misc.forsale' 'sci.electronics']\n",
      "*************************************\n",
      "Mensaje recuperado 0:\n",
      " From: queloz@bernina.ethz.ch (Ronald Queloz)\n",
      "Subject: Hypercard for UNIX\n",
      "Organization: Swiss Federal Institute of Technology (ETH), Zurich, CH\n",
      "Lines: 10\n",
      "\n",
      "Hi netlanders,\n",
      "\n",
      "Does anybody know if there is something like Macintosh Hypercard for any UNIX \n",
      "platform?\n",
      "\n",
      "\n",
      "Thanks in advance\n",
      "\n",
      "\n",
      "Ron.\n",
      "\n",
      "*************************************\n",
      "Mensaje recuperado 1:\n",
      " From: gt4661a@prism.gatech.EDU (gt4661a gt4661a PAOLO,MARC ANTHONY)\n",
      "Subject: Computer For Sale\n",
      "Distribution: atl\n",
      "Organization: Georgia Institute of Technology\n",
      "Lines: 5\n",
      "\n",
      "-- \n",
      "PAOLO,MARC ANTHONY\n",
      "Georgia Institute of Technology, Atlanta Georgia, 30332\n",
      "uucp:     ...!{allegra,amd,hplabs,ut-ngp}!gatech!prism!gt4661a\n",
      "Internet: gt4661a@prism.gatech.edu\n",
      "\n",
      "*************************************\n",
      "Mensaje recuperado 2:\n",
      " From: harpe@netnews.louisville.edu (Mike Harpe)\n",
      "Subject: WANTED: Protel EasyTrax for the MAC\n",
      "Organization: University of Louisville\n",
      "Lines: 12\n",
      "\n",
      "The title says it all.  Contact me via EMAIL if you would can help me out...\n",
      "\n",
      "Mike Harpe\n",
      "University of Louisville\n",
      "\n",
      "P.S.  I KNOW IT IS DISCONTINUED.  I want someone who would like to sell\n",
      "      an old copy.\n",
      "-- \n",
      "Michael Harpe, Programmer/Analyst      Information Technology, Ormsby Bldg.\n",
      "harpe@hermes.louisville.edu            University of Louisville\n",
      "(502)588-5542                          Louisville, Ky. 40292\n",
      "\"He's not a man, he's a remorseless eating machine!\" - The Simpsons\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostramos los mesajes recuperados para la segunda consulta de la clase comp.sys.mac.hardware\n",
    "worst_class_precission(train_data.data, train_vector_data, train_data.target, messages[4][1], vector_messages[4][1], train_data.target_names, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las tres clases con las que más se ha confundido esta consultas son con _comp.windows.x, misc.forsale, sci.electronics_, las tres tienen una cosa en común: la tecnología: ya sea porque dos de esas clases están basadas en tecnolgía y ordenadores o porque el mensaje de clase _misc.forsale_ hable sobre la venta de un ordenador. Los tres mensajes vienen de partes de instituciones de tecnología(ya sean universidades o institutos) y es lógico la confusión de clase entre la consulta y los resultados. Además el mensaje de consulta hace muy poca referencia a macs mientras que usa bastantes palabras de termino tçecnologico, y particularmente de ordenadores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Bolsa de palabras con TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a repetir el mismo proceso del apartado anterior, pero esta vez vamos a vectorizar los mensajes con TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Pasamos el diccionario a una lista\n",
    "with open('words.txt') as f:\n",
    "    dictionary = f.read().splitlines()\n",
    "\n",
    "# Creamos la bolsa de palabras\n",
    "vectorizer = CountVectorizer(binary=False, ngram_range=(1,1), vocabulary=dictionary, stop_words='english')  \n",
    "\n",
    "# Entrenamos al modelo\n",
    "train_vector_data = vectorizer.fit_transform(train_data.data)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# Convertimos la frecuencia a TF-IDF\n",
    "tfider = TfidfTransformer()\n",
    "train_preprocessed = tfider.fit_transform(train_vector_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 466551)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos los mismos mensajes seleccionados anteriormente\n",
    "# Los vectorizamos, esta vez usando TF-IDF\n",
    "vector_messages = vectorize_messages(messages, vectorizer, tfider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: alt.atheism  Precission:  22.222222222222218\n",
      "Class 1: comp.graphics  Precission:  11.111111111111109\n",
      "Class 2: comp.os.ms-windows.misc  Precission:  11.111111111111109\n",
      "Class 3: comp.sys.ibm.pc.hardware  Precission:  66.66666666666667\n",
      "Class 4: comp.sys.mac.hardware  Precission:  33.33333333333333\n",
      "Class 5: comp.windows.x  Precission:  33.33333333333333\n",
      "Class 6: misc.forsale  Precission:  44.444444444444436\n",
      "Class 7: rec.autos  Precission:  44.444444444444436\n",
      "Class 8: rec.motorcycles  Precission:  77.77777777777777\n",
      "Class 9: rec.sport.baseball  Precission:  100.0\n",
      "Class 10: rec.sport.hockey  Precission:  100.0\n",
      "Class 11: sci.crypt  Precission:  55.55555555555554\n",
      "Class 12: sci.electronics  Precission:  44.444444444444436\n",
      "Class 13: sci.med  Precission:  77.77777777777777\n",
      "Class 14: sci.space  Precission:  100.0\n",
      "Class 15: soc.religion.christian  Precission:  77.77777777777777\n",
      "Class 16: talk.politics.guns  Precission:  66.66666666666666\n",
      "Class 17: talk.politics.mideast  Precission:  77.77777777777777\n",
      "Class 18: talk.politics.misc  Precission:  66.66666666666666\n",
      "Class 19: talk.religion.misc  Precission:  33.333333333333336\n"
     ]
    }
   ],
   "source": [
    "# Precision con nivel de exhaustividad = 3\n",
    "cosine_similarity_precission(train_preprocessed, train_data.target, vector_messages, train_data.target_names, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: alt.atheism  Precission:  26.666666666666668\n",
      "Class 1: comp.graphics  Precission:  30.0\n",
      "Class 2: comp.os.ms-windows.misc  Precission:  30.0\n",
      "Class 3: comp.sys.ibm.pc.hardware  Precission:  60.0\n",
      "Class 4: comp.sys.mac.hardware  Precission:  13.333333333333334\n",
      "Class 5: comp.windows.x  Precission:  40.0\n",
      "Class 6: misc.forsale  Precission:  30.0\n",
      "Class 7: rec.autos  Precission:  46.666666666666664\n",
      "Class 8: rec.motorcycles  Precission:  76.66666666666667\n",
      "Class 9: rec.sport.baseball  Precission:  93.33333333333333\n",
      "Class 10: rec.sport.hockey  Precission:  100.0\n",
      "Class 11: sci.crypt  Precission:  36.666666666666664\n",
      "Class 12: sci.electronics  Precission:  60.0\n",
      "Class 13: sci.med  Precission:  63.333333333333336\n",
      "Class 14: sci.space  Precission:  80.0\n",
      "Class 15: soc.religion.christian  Precission:  60.0\n",
      "Class 16: talk.politics.guns  Precission:  33.333333333333336\n",
      "Class 17: talk.politics.mideast  Precission:  50.0\n",
      "Class 18: talk.politics.misc  Precission:  46.666666666666664\n",
      "Class 19: talk.religion.misc  Precission:  30.0\n"
     ]
    }
   ],
   "source": [
    "# Precision con nivel de exhaustividad = 10\n",
    "cosine_similarity_precission(train_vector_data, train_data.target, vector_messages, train_data.target_names, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, usando TD-IDF para ponderar el peso de los términos varía la precisión media de la mayoría de las clases. Con un nivel de exhaustividad 3 hay 5 clases que han empeorado(_alt.atheism, comp.graphics, comp.os.ms-windows.misc,misc.forsale,rec.motorcycles_),9 que han mejorado(_comp.sys.ibm.pc.hardware, comp.sys.mac.hardware, rec.autos, rec.sport.baseball,rec.sport.hockey, sci.space, talk.politics.guns, talk.politics.mideast, talk.politics.misc_) y 6 que se han quedado igual(_comp.windows.x, sci.crypt, sci.electronics, sci.med, soc.religion.christian, talk.religion.misc_).\n",
    "En cambio, con un nivel de exhaustividad 10 hay tan solo 2 clases que han empeorado(_misc.forsale y talk.politics.guns_) y 2 que se han quedado igual(_comp.os.ms-windows.misc y sci.crypt_), mientras que el resto de clases han mejorado en precision media."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver un ejemplo de una clase que ha mejorado en precision con el uso de tf/idf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONSULTA:\n",
      " From: s9131783@valiant.vut.EDU.AU (Robert B Harvey)\n",
      "Subject: Disabling the Eject on a Mac SE\n",
      "Organization: Victoria University Of Technology, Melbourne, Australia\n",
      "Lines: 13\n",
      "\n",
      "I'm trying to find a program that will stop the Macs from spitting out\n",
      "their Boot Disk. I was told one exists but I can't find it.\n",
      "\n",
      "Anyone know where I can find it?\n",
      "\n",
      "Thanks\n",
      "\n",
      "Robert Harvey\n",
      "Duty Programmer\n",
      "Information Technology\n",
      "Victoria University\n",
      "\n",
      "s9131783@valiant.vut.edu.au\n",
      "\n",
      "*************************************\n",
      "Clases recuperadas: ['comp.sys.mac.hardware' 'misc.forsale' 'comp.sys.mac.hardware']\n",
      "*************************************\n",
      "Mensaje recuperado 0:\n",
      " From: andy@ie.utoronto.ca (Andy Sun)\n",
      "Subject: Re: Centris 650 to Decstation E-net adapter\n",
      "Organization: University of Toronto, Department of Industrial Engineering\n",
      "Lines: 86\n",
      "\n",
      ">pnsf01dw@smucs1.umassd.edu (Dennis J. Wilkinson) writes:\n",
      ">Not necessarily a thrid-party adapter; Apple does manufacture transceivers\n",
      ">for thinWire and 10BaseT (twisted pair) cable media, as well as an AUI\n",
      ">(Attachment Unit Interface) transciever. They run at ~$100 each. If you use\n",
      ">thinWire or 10BaseT, you'll probably also need terminators (Apple's\n",
      ">transceivers are self-terminated, if I remember correctly, but I have no\n",
      ">idea about DECs). \n",
      "\n",
      "The third-party media adapters are usually cheaper (at least in Toronto) than\n",
      "Apple's. I bought the adapters from Asante instead of Apple.\n",
      "\n",
      "gurman@umbra.gsfc.nasa.gov (Joseph B. Gurman) writes:\n",
      ">    The DECstation 5000 Models 200 and 240 come with ThinWire only\n",
      ">(can't say for certain about the Models 125 and 133), so your best bet\n",
      "\n",
      "That's not true. Only the DECstation 5000/200 comes with a Thinwire\n",
      "(BNC, coaxial) Ethernet connector. The 5000/25, 5000/133 and 5000/240\n",
      "all have a single 15-pin AUI Ethernet connector only. I distinctly\n",
      "remembered this because when got the 5000/200 first and I thought all\n",
      "of them are going to be Thinwire. I eventually had to go back and ordered\n",
      "DESTAs (DEC's oversized version of an AUI-to-BNC adapter that MUST be used\n",
      "with a transciever cable) for the rest of the stations.\n",
      "\n",
      "My advise to the very original poster (Beverly?) is:\n",
      "\n",
      "(1) If all you want is to create a LAN with two workstations and won't add\n",
      "    machines to it EVER, go for Thinwire regardless of the media type. Going\n",
      "    for UTP (unshielded twisted pair) wiring requires a concentrator which\n",
      "    means extra money and I believe these units come with at least 6 ports.\n",
      "    As for Thicknet, it's a nightmare and cabling is expensive. Avoid it\n",
      "    unless you have no choice (e.g. the two machines are two floors parts).\n",
      "\n",
      "(2) On the Mac side, you will need:\n",
      "    - one Thinwire media adapter (from Apple or third-party).\n",
      "    - MacX (make sure you get version 1.2; 1.1.7 won't run on System 7.1).\n",
      "    - MacTCP (which comes with MacX; if you get MacX v1.2, you should be\n",
      "      getting MacTCP v1.1.1 with it. Don't use earlier versions on a Centris).\n",
      "    - you may or may not need a 25ohm terminator depending on the\n",
      "      Thinwire media adapter. So just ask the sales if the adapter is\n",
      "      self-terminated or not.\n",
      "    - configure MacTCP to use \"Ethernet\".\n",
      "\n",
      "(3) On the DECstation side, you will need:\n",
      "    - for a Model 200, you will only need a T-connector.\n",
      "    - for Models 25, 125, 133, 240, you will need an AUI-to-BNC adapter.\n",
      "      Get one that can be plugged in directly to the AUI port of the\n",
      "      DECstation. This way you save the cost of a transciever cable\n",
      "      (a 15-pin AUI male to a 15-pin AUI female cable).\n",
      "    - get a 25ohm terminator.\n",
      "\n",
      "Your two-machine network will look like this:\n",
      "\n",
      "\n",
      "       ##T----------------------------------------------[]\n",
      "      +-----+                                           |\n",
      "      |     |                                           |\n",
      "      +-----+                                         +-----+\n",
      "                                                      |     |\n",
      "                                                      +-----+\n",
      "    DECstation                                        Centris\n",
      "     5000/200                                           650\n",
      "                              OR\n",
      "\n",
      "       ##T----------------------------------------------[]\n",
      "        {=}                                             |\n",
      "      +-----+                                           |\n",
      "      |     |                                         +-----+\n",
      "      +-----+                                         |     |\n",
      "                                                      +-----+\n",
      "    DECstation                                        Centris\n",
      "5000/25,125,133,240                                     650\n",
      "         \n",
      "   ##    -> 25ohm terminator\n",
      "   T     -> T connector\n",
      "   ---   -> Thinwire (RG58 coaxial cable)\n",
      "   {=}   -> AUI-to-BNC (i.e. Thick-to-Thin) adapter\n",
      "   []    -> Thickwire media adapter (assuming self-terminated)\n",
      "   |\n",
      "   |\n",
      "\n",
      "Andy\n",
      "-- \n",
      "Andy Sun (andy@ie.utoronto.ca)          4 Taddle Creek Road, Toronto\n",
      "Computing Coordinator                   Ontario, Canada. M5S 1A4\n",
      "Department of Industrial Engineering    Phone: (416) 978-8830\n",
      "University of Toronto                   Fax:   (416) 978-3453\n",
      "\n",
      "*************************************\n",
      "Mensaje recuperado 1:\n",
      " From: xanadu@seanews.akita.com (Dan Scherer)\n",
      "Subject: PS/2 Stuff\n",
      "Organization: SEANEWS - Seattle Public Access News + Mail\n",
      "Lines: 30\n",
      "\n",
      "Misc. P2/2 Stuff!\n",
      "\n",
      " CARDS: (Micro Channel)\n",
      "  (6) Arcnet, Coax, 83X9648. Net Cards.\n",
      "  (3) Serial Adapter. P/N: 90X8459\n",
      "  (2) Parallel Adapters. P/N: 72X6753\n",
      "  (2) CoProcessor?? P/N: 83X7488\n",
      "  (2) Memory Expansion Option. P/N: 90X9507\n",
      "  Expanded Memory Adapter w/2Mb. P/N: 61X6752\n",
      "  Expanded memory Adapter, 0k, P/N: 90X8799\n",
      "  Alloy FTC500/MCA Tape adapter.\n",
      "\n",
      " DRIVES: (Hard & Floppy)\n",
      "  30 Mb HDD, P/N: 90X9403  Model WD-336R\n",
      "  60 Mb HDD, P/N: 6128282, Model WD-387T\n",
      "  1.44 FDD, P/N: 15F7503, EC #A79541\n",
      "  1.44 FDD, P/N: 15F7503, EC #88086\n",
      "\n",
      " This is what I have aquired over the past few years in PS/2 \n",
      "components...\n",
      " I have posted the part #'s, so if you have any questions as to what a\n",
      " component is, you can call IBM and find out! (I have no idea!!!)\n",
      " Make me an offer! Trades welcome!\n",
      "   Dan Scherer\n",
      "   (206) 453-5215 Voice\n",
      "   (206) 996-8350 Pager\n",
      "\n",
      "--\n",
      "[] SEANEWS [] Seattle Public Access Usenet News + Mail [] +1 206 747 NEWS []\n",
      "xanadu@seanews.akita.com\n",
      "\n",
      "*************************************\n",
      "Mensaje recuperado 2:\n",
      " From: Mel_Shear@maccomw.uucp\n",
      "Subject: Adapter Cable for VGA Monitors\n",
      "Lines: 51\n",
      "\n",
      "Does anyone know who makes a cable or adapter that is wired according to\n",
      "Apple's specs that forces the external output on LC's and the Powerbook's\n",
      "160/180 and Duo 230 into a true VGA style output signal? The NEC Adapter does\n",
      "not do this since their monitors are multisync they just route the signal into\n",
      "the correct pinout but do not switch the Macs output into VGA mode.\n",
      "\n",
      "Do I have to make one of these or does someone already have one made-up??\n",
      "\n",
      "The following is the Apple spec for the LC cpu VGA Cable adapter. I'm assuming\n",
      "that the Powerbooks/Duos will work with the same adapter(?);\n",
      "\n",
      "\n",
      "Macintosh LC to VGA\n",
      " \n",
      "The Macintosh LC can supply a 640 x 480, VGA timed signal for use with VGA\n",
      "monitors by using an adapter cable.  The standard Macintosh LC supports VGA to\n",
      "16 colors, and with the optional 512K VRAM SIMM, the VGA monitor is supported\n",
      "to 256 colors.\n",
      " \n",
      "Note:     The Macintosh LC supplies signals capable of driving TTL level\n",
      "          inputs.  However, some low impedance input VGA monitors do not work\n",
      "          with the Macintosh LC.\n",
      " \n",
      "To connect a Macintosh LC to a VGA monitor, you need to make an adapter cable\n",
      "from the Macintosh LC video connector to the VGA monitor.  Following is the\n",
      "pinout description for the adapter cable:\n",
      " \n",
      "Macintosh LC        VGA\n",
      "Video Connector     Pin     Signal Name\n",
      "---------------     ----    -----------\n",
      "1                   6       Red ground\n",
      "2                   1       Red video signal\n",
      "5                   2       Green video signal\n",
      "6                   7       Green ground\n",
      "9                   3       Blue video signal\n",
      "13                  8       Blue ground\n",
      "15                  13      /HSYNC\n",
      "12                  14      /VSYNC\n",
      "14                  10      HSYNC ground\n",
      "7,10                nc      SENSE1 & SENSE2 tied together\n",
      " \n",
      "VGA monitors are identified by shorting pin 7 to pin 10 on the Macintosh LC\n",
      "video connector.  The Macintosh LC grounds pin 7 on its video connector, which\n",
      "results in pulling down pin 10 and gives the correct monitor ID for a VGA\n",
      "monitor.\n",
      "\n",
      "***************************************************************************\n",
      "This message was created on MCW BBS a jointly supported by\n",
      "New Orleans Mac User Group & National Home & School User Group\n",
      "user@maccomw.uucp        The views expressed in this posting those of the individual author only.\n",
      "***************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Uilkizamos la clase comp.sys.mac.hardware, la clase con peor precision que ha mejorado\n",
    "worst_class_precission(train_data.data, train_vector_data, train_data.target, messages[4][1], vector_messages[4][2], train_data.target_names, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver los resultados de la consulta han mejorado mostrando mensajes de clase _comp.sys.mac.hardware_, esto se debe a que hemos ponderado mediante td/idf dando más peso a los términos más específicos de la clase, mientras que anteriormente esta clase se confundía con otras de tecnología y electrónica debido al uso de palabras más generales relacionadas con ordenadores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
