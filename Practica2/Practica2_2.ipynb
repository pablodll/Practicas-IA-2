{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Practica 2.2**\n",
    "#### _Alberto García Doménech - Pablo Daurell Marina_ (Grupo 10)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2 (Recuperación de información)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta práctica vamos a utilizar el dataset ```20 Newsgroup``` de Scikit-learn, que contiene textos de un foro sobres distintos temas muy variados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training texts: 11314\n",
      "Test texts: 7532\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el dataset\n",
    "train_data = fetch_20newsgroups(subset='train', shuffle=True, random_state=42)\n",
    "test_data = fetch_20newsgroups(subset='test')\n",
    "\n",
    "print(\"Training texts:\", len(train_data.data))\n",
    "print(\"Test texts:\", len(test_data.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver algunos ejemplos de los textos que hay en el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MENSAJE:\n",
      " From: shd2001@andy.bgsu.edu (Sherlette Dixon)\n",
      "Subject: Christianity & Atheism:  an update\n",
      "Organization: BGSU\n",
      "Lines: 32\n",
      "\n",
      "First, I would like to thank all who sent me their opinions on the matter\n",
      "at hand.  All advice was taken to heart, if not directly used.  My friend\n",
      "found out about the matter quite accidently.  After reading some of my\n",
      "mail, I quit from the mail reader & went about my business.  I must have\n",
      "trashed my mail improperly, because he got on the same terminal the next\n",
      "day & saw my old messages.  He thought they were responses to a post he\n",
      "placed in alt.atheism earlier that week, so he read some of them before\n",
      "realizing that they were for me.  I got a message from him the next day; he\n",
      "apologized for reading my mail & said that he did not want to appear to be\n",
      "a snoop.  He said that he would be willing to talk to me about his views &\n",
      "didn't mind doing so, especially with a friend.  So we did.  I neither\n",
      "changed his mind nor did he change mine, as that was not the point.  Now he\n",
      "knows where I'm coming from & now I know where he's coming from.  And all\n",
      "that I can do is pray for him, as I've always done.\n",
      "\n",
      "I believe the reason that he & I \"click\" instead of \"bash\" heads is because\n",
      "I see Christianity as a tool for revolution, & not a tool for maintaining\n",
      "the status quo.  To be quite blunt, I have more of a reason to reject God\n",
      "than he does just by the fact that I am an African-American female. \n",
      "Christianity & religion have been used as tools to separate my people from\n",
      "the true knowledge of our history & the wealth of our contributions to the\n",
      "world society.  The \"kitchen of heaven\" was all we had to look forward to\n",
      "during the slave days, & this mentality & second-class status still exists\n",
      "today.  I, too, have rejected\n",
      "an aspect of Christianity----that of the estabished church.  Too much\n",
      "hypocricy exists behind the walls of \"God's house\" beginning with the\n",
      "images of a white Jesus to that of the members:  praise God on Sunday &\n",
      "raise hell beginning Monday.  God-willing, I will find a church home where\n",
      "I can feel comfortable & at-home, but I don't see it happening anytime\n",
      "soon.\n",
      "\n",
      "Sherlette \n",
      "\n",
      "CLASE:  soc.religion.christian\n"
     ]
    }
   ],
   "source": [
    "print('MENSAJE:\\n',train_data.data[120])\n",
    "print('CLASE: ', train_data.target_names[train_data.target[120]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MENSAJE:\n",
      " From: ab245@cleveland.Freenet.Edu (Sam Latonia)\n",
      "Subject: Re: Need phone number for Western Digital (ESDI problem)\n",
      "Organization: Case Western Reserve University, Cleveland, Ohio (USA)\n",
      "Lines: 5\n",
      "NNTP-Posting-Host: slc10.ins.cwru.edu\n",
      "\n",
      "\n",
      "Western Digital 1-800-832-4778.....Sam\n",
      "-- \n",
      "Gosh..I think I just installed a virus..It was called MS DOS6...\n",
      "Don't copy that floppy..BURN IT...I just love Windows...CRASH...\n",
      "\n",
      "CLASE:  comp.sys.ibm.pc.hardware\n"
     ]
    }
   ],
   "source": [
    "print('MENSAJE:\\n',train_data.data[42])\n",
    "print('CLASE: ', train_data.target_names[train_data.target[42]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Bolsa de palabras binaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertimos el conjunto de datos en una bolsa de palabras, binaria y con n-gramas (1,1), usaremos como vocabulario el diccionario ```words.txt``` (https://github.com/dwyl/english-words/blob/master/words.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466551\n"
     ]
    }
   ],
   "source": [
    "# Pasamos el diccionario a una lista\n",
    "with open('words.txt') as f:\n",
    "    dictionary = f.read().splitlines()\n",
    "\n",
    "# Creamos la bolsa de palabras\n",
    "vectorizer = CountVectorizer(binary=False, ngram_range=(1,1), vocabulary=dictionary, stop_words='english')  \n",
    "\n",
    "# Entrenamos al modelo\n",
    "train_vector_data = vectorizer.fit_transform(train_data.data)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "print(len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 466551)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_vector_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_messages(data, target, target_names, n):\n",
    "    '''\n",
    "    Selecciona n mensajes de cada clase\n",
    "    Return: Matriz con una fila por cada clase y tres mensajes por cada fila\n",
    "    '''\n",
    "    messages = []\n",
    "    # Recorremos todas las clases\n",
    "    for i in range(len(target_names)):\n",
    "        # Seleccionamos las posiciones correspondientes a los mensajes de la clase i\n",
    "        indices = np.asarray(np.where(target == i)).ravel()\n",
    "        # Cogemos los n primeros mensajes de la clase i\n",
    "        aux = np.take(data, indices)[0:n]\n",
    "        messages.append(aux)\n",
    "    \n",
    "    return np.array(messages)\n",
    "\n",
    "def vectorize_messages(data, vectorizer):\n",
    "    '''\n",
    "    Recibe una matriz de textos y convierte cada texto a una bolsa de palabras,\n",
    "    usando un vectorizador previamente entrenado\n",
    "    Return: Matriz con una fila por cada clase y en cada fila otra matriz con los mensajes vectorizados\n",
    "    '''\n",
    "    # Recorremos todas las filas (una por cada clase)\n",
    "    vector_data = []\n",
    "    for i in range(np.shape(data)[0]):\n",
    "        aux = vectorizer.transform(data[i, :])\n",
    "        vector_data.append(aux)\n",
    "        \n",
    "    return np.array(vector_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos, del conjunto de test, 3 mensajes de cada una de las 20 clases:\n",
    "messages = select_messages(test_data.data, test_data.target, test_data.target_names, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizamos los mensajes seleccionados\n",
    "vector_messages = vectorize_messages(messages, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(vector_messages[0])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Borrar cuando este hecho vvv\n",
    "Considera una clase, por ejemplo, politics.\n",
    "\n",
    "1. Para cada uno de los mensajes de test de la clase politics se calcula la similitud del coseno con todos y cada uno los mensajes de entrenamiento.\n",
    "2. Se ordenan dichas distancias de mayor y menor y se cogen las X primeras, que son las X que más se parecen. Recuperamos los mensajes correspondientes a las X mayores similitudes del coseno.\n",
    "3. Se identifica la clase de los X primeros mensajes y se calcula la precisión, contando el porcentaje de ellos que son de la clase politics.\n",
    "4. Los pasos 1-3 se repiten para los tres mensajes de test de la clase politics. Una vez calculadas las tres precisiones a nivel X, se calcula su media, que es lo que se nos está pidiendo.\n",
    "5. Los pasos 1-4 debes repetirlos para los distintos niveles de precisión X que se pide.\n",
    "\n",
    "Todo el proceso debes repetirlo para cada una de las clases, es decir, de los grupos de noticias.\n",
    "#### Borrar cuando este hecho ^^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def cosine_similarity_precission(data, target, messages, target_names, X):\n",
    "    '''\n",
    "    Calcula la similitud del coseno de cada mensaje con todos los mensajes de \"data\" y\n",
    "    y calcula la precision de cada clase, a un nivel de exhaustividad X.\n",
    "    '''\n",
    "    for i in range(len(messages)): # Recorremos cada clase\n",
    "        precission = 0\n",
    "        for m in vector_messages[i]: # Recorremos cada mensaje\n",
    "            # Calculamos la similitud del coseno de m con los textos de entrenamiento\n",
    "            cos_sim = cosine_similarity(m, data).ravel()\n",
    "\n",
    "            # Ordenamos los resultados y cogemos los indices de los X mayores resultados\n",
    "            max_args = np.flip(np.argsort(cos_sim))[0:X]\n",
    "\n",
    "            #  max_values = np.take(cos_sim, max_args)         \n",
    "            #  Recuperamos los mensajes con mayor similitud\n",
    "            # retrieved_docs = np.take(data, max_args)\n",
    "\n",
    "            # Identificamos la clase de los mensajes con mayor similitud\n",
    "            retrieved_classes = np.take(target, max_args)\n",
    "\n",
    "            # Calculamos la precision (%) para este mensaje y lo acumulamos a las anteriores\n",
    "            precission += (np.count_nonzero(retrieved_classes == i) / len(retrieved_classes)) * 100\n",
    "\n",
    "\n",
    "        # Calculamos la media de los porcentajes obtenidos\n",
    "        precission /= np.shape(vector_messages[i])[0]\n",
    "        \n",
    "        print('Class: {} '.format(i), target_names[i])\n",
    "        print('Precission: ', precission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0  alt.atheism\n",
      "Precission:  33.333333333333336\n",
      "Class: 1  comp.graphics\n",
      "Precission:  22.222222222222218\n",
      "Class: 2  comp.os.ms-windows.misc\n",
      "Precission:  22.222222222222218\n",
      "Class: 3  comp.sys.ibm.pc.hardware\n",
      "Precission:  55.55555555555555\n",
      "Class: 4  comp.sys.mac.hardware\n",
      "Precission:  0.0\n",
      "Class: 5  comp.windows.x\n",
      "Precission:  33.33333333333333\n",
      "Class: 6  misc.forsale\n",
      "Precission:  77.77777777777777\n",
      "Class: 7  rec.autos\n",
      "Precission:  33.333333333333336\n",
      "Class: 8  rec.motorcycles\n",
      "Precission:  88.88888888888887\n",
      "Class: 9  rec.sport.baseball\n",
      "Precission:  77.77777777777777\n",
      "Class: 10  rec.sport.hockey\n",
      "Precission:  66.66666666666667\n",
      "Class: 11  sci.crypt\n",
      "Precission:  55.55555555555554\n",
      "Class: 12  sci.electronics\n",
      "Precission:  44.444444444444436\n",
      "Class: 13  sci.med\n",
      "Precission:  77.77777777777777\n",
      "Class: 14  sci.space\n",
      "Precission:  77.77777777777777\n",
      "Class: 15  soc.religion.christian\n",
      "Precission:  77.77777777777777\n",
      "Class: 16  talk.politics.guns\n",
      "Precission:  55.55555555555554\n",
      "Class: 17  talk.politics.mideast\n",
      "Precission:  22.222222222222218\n",
      "Class: 18  talk.politics.misc\n",
      "Precission:  33.33333333333333\n",
      "Class: 19  talk.religion.misc\n",
      "Precission:  33.33333333333333\n"
     ]
    }
   ],
   "source": [
    "# Precision con nivel de exhaustividad = 3\n",
    "cosine_similarity_precission(train_vector_data, train_data.target, vector_messages, train_data.target_names, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0  alt.atheism\n",
      "Precission:  23.333333333333332\n",
      "Class: 1  comp.graphics\n",
      "Precission:  20.0\n",
      "Class: 2  comp.os.ms-windows.misc\n",
      "Precission:  30.0\n",
      "Class: 3  comp.sys.ibm.pc.hardware\n",
      "Precission:  50.0\n",
      "Class: 4  comp.sys.mac.hardware\n",
      "Precission:  6.666666666666667\n",
      "Class: 5  comp.windows.x\n",
      "Precission:  30.0\n",
      "Class: 6  misc.forsale\n",
      "Precission:  56.666666666666664\n",
      "Class: 7  rec.autos\n",
      "Precission:  30.0\n",
      "Class: 8  rec.motorcycles\n",
      "Precission:  73.33333333333333\n",
      "Class: 9  rec.sport.baseball\n",
      "Precission:  76.66666666666667\n",
      "Class: 10  rec.sport.hockey\n",
      "Precission:  56.666666666666664\n",
      "Class: 11  sci.crypt\n",
      "Precission:  36.666666666666664\n",
      "Class: 12  sci.electronics\n",
      "Precission:  50.0\n",
      "Class: 13  sci.med\n",
      "Precission:  53.333333333333336\n",
      "Class: 14  sci.space\n",
      "Precission:  73.33333333333333\n",
      "Class: 15  soc.religion.christian\n",
      "Precission:  50.0\n",
      "Class: 16  talk.politics.guns\n",
      "Precission:  40.0\n",
      "Class: 17  talk.politics.mideast\n",
      "Precission:  26.666666666666668\n",
      "Class: 18  talk.politics.misc\n",
      "Precission:  23.333333333333332\n",
      "Class: 19  talk.religion.misc\n",
      "Precission:  16.666666666666668\n"
     ]
    }
   ],
   "source": [
    "# Precision con nivel de exhaustividad = 10\n",
    "cosine_similarity_precission(train_vector_data, train_data.target, vector_messages, train_data.target_names, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay una gran diferencia entre los valores de precision medios de las diferentes clases, siendo la mayor diferencia de un 88.88% con un nivel de exhaustividad 3 y de un 70% con un nivel de exhaustividad de 10. Esta clara diferencia puede venir por la ausencia de terminos especificos de la clase que estamos buscando en las consultas lo que puede llevar a una confusión entre clases. Por ejemplo, la clase con menor precisión es _comp.sys.mac.hardware_ con un 0% de precisión con nivel 3 de exhaustividad y un 6.67% con nivel 10, este nivel tan bajo de precisión seguramente se deba a que las consultas elegidas se confunden con otras clases que traten casi el mismo tema, como es el caso de _comp.sys.ibm.pc.hardware_.\n",
    "Mientras que las clases que mejor precisión media tienen (_rec.motorcycles , rec.sport.basketball_) seguramente se deba a que las consultas tienen términos más específicos que las clasifiquen como las clases a las que pertenecen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-40-55ef48d47d0b>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-40-55ef48d47d0b>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    for i = 4: # in range(len(messages)): # Recorremos cada clase SOLO LA QUE PEOR PRECISION TIENE\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def worst_class_precission(data, target, messages, target_names, X):\n",
    "    '''\n",
    "    Calcula la similitud del coseno de cada mensaje con todos los mensajes de \"data\" y\n",
    "    y calcula la precision de cada clase, a un nivel de exhaustividad X.\n",
    "    '''\n",
    "    for i in range(len(messages)): # Recorremos cada clase SOLO LA QUE PEOR PRECISION TIENE\n",
    "        precission = 0\n",
    "        for m in vector_messages[i]: # Recorremos cada mensaje\n",
    "            # Calculamos la similitud del coseno de m con los textos de entrenamiento\n",
    "            cos_sim = cosine_similarity(m, data).ravel()\n",
    "\n",
    "            # Ordenamos los resultados y cogemos los indices de los X mayores resultados\n",
    "            max_args = np.flip(np.argsort(cos_sim))[0:X]\n",
    "\n",
    "            #  max_values = np.take(cos_sim, max_args)         \n",
    "            #  Recuperamos los mensajes con mayor similitud\n",
    "            retrieved_docs = np.take(data, max_args)\n",
    "\n",
    "            # Identificamos la clase de los mensajes con mayor similitud\n",
    "            retrieved_classes = np.take(target, max_args)\n",
    "\n",
    "            # Calculamos la precision (%) para este mensaje y lo acumulamos a las anteriores\n",
    "#             precission += (np.count_nonzero(retrieved_classes == i) / len(retrieved_classes)) * 100\n",
    "\n",
    "\n",
    "#     mostramos los mensajes con mayor similitud\n",
    "        print(retrieved_docs)\n",
    "\n",
    "\n",
    "        # Calculamos la media de los porcentajes obtenidos\n",
    "#         precission /= np.shape(vector_messages[i])[0]\n",
    "#         print('Class: {} '.format(i), target_names[i])\n",
    "#         print('Precission: ', precission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
